---
title: "campaign_food_spending"
author: "Dylan Manfre"
date: "2023-08-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

#libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
#install.packages("ipumsr")
library(ipumsr)
```

*** Early notes from Aug. 23 ***

- Years filtered for: 2011 to today
- States filtered fsor: DC, MD, VA
- Search terms I used in the FEC.gov site.
  - food, drinks, meals, catering, dining, beverage, meeting, events (produced a dataset with 274,352 results)
  - Link: https://www.fec.gov/data/disbursements/?data_type=processed&two_year_transaction_period=2012&two_year_transaction_period=2014&two_year_transaction_period=2016&two_year_transaction_period=2018&two_year_transaction_period=2020&two_year_transaction_period=2022&two_year_transaction_period=2024&min_date=01%2F01%2F2011&max_date=12%2F31%2F2024&recipient_state=DC&recipient_state=MD&recipient_state=VA&disbursement_description=FOOD&disbursement_description=DRINKS&disbursement_description=MEALS&disbursement_description=CATERING&disbursement_description=DINING&disbursement_description=BEVERAGE&disbursement_description=MEETING&disbursement_description=EVENTS
  

  

- We want to identify the purpose category as "Fundraising" or another term and make sure it doesn't say "travel" so we exclude those unnecessary transactions.



```{r}

# loading in the campaign_food_data.csv
campaign_food_data <- read_csv("data/campaign_food_data.csv")
head(campaign_food_data)

```


** I put in 7 filters to the FEC site with the above link. Shouldn't then there only be 7 categories that show up? **

```{r}
#counts for categories
campaign_food_data %>% 
group_by(disbursement_description) %>% 
count() %>% 
arrange(desc(n))

#recipient totals
category_totals <- campaign_food_data %>% 
group_by(recipient_name, recipient_state) %>% 
summarize(total_spent = sum(disbursement_amount)) %>% 
arrange(desc(total_spent))

#state totals
state_totals <-  campaign_food_data %>% 
group_by(recipient_state) %>% 
summarize(total_spent = sum(disbursement_amount)) %>% 
arrange(desc(total_spent))
#why is DC not showing up?
#Look for the NAs in the dataset

#use this block to try and filter for the NAs
campaign_food_data <- campaign_food_data %>% 
filter(!is.na(disbursement_amount))
#omitted image_number: 12020611921 becasue it showed up as a NA and FEC site said it was $0 anyway.
```

```{r}
#trying to see how many transactions there are in the years, based on the quater of the year?

#Then try to find out how much money was spent in that quarter
#Try to set up the columns: YEAR, QUARTER, NO. OF TRANSACTIONS, Q_TOTAL

#Which year had the most transactions
year_totals <-campaign_food_data %>% 
group_by(report_year) %>% 
count() %>%
arrange(desc(n))
#2018 had most transactions

#Showing which month was the most money spent
month_totals <- campaign_food_data %>% 
  mutate(month = floor_date(disbursement_date, "month")) %>% 
  group_by(month) %>% 
  summarise(total_amount = sum(disbursement_amount)) %>% 
  arrange(desc(total_amount))
# Nov. 2016 was when the msot money was spent... Trump was elected in this month. 
# Lots spent here for a few reasons: final stretch of campaigning,
# Nov doesnt appear again until No. 27 at Nov. 2018

# This codeblock is trying to filter and show the totals for all of Novembers. 

nov_totals <- campaign_food_data %>% 
  mutate(month = floor_date(disbursement_date, "month")) %>% 
  group_by(month) %>% 
  summarise(total_amount = sum(disbursement_amount)) %>% 
  filter(month(month) == 11) %>% 
  arrange(desc(total_amount))

```

** Should I use Open Refine to standardize some of the disbursement_descriptions
List of ones to standardist: FOOD AND BEVERAGE, FOOD & BEVERAGE, FOOD/BEVERAGES, FOOD / BEVERAGES, FOOD AND MEALS, FOOD & BEV, FOOD AND BEVERAGE EXPENSE

** RESTURANT MEALS IS A GOOD ONE TO HONE IN ON **




*** Generating new data from the Bulk Downloads section of FEC.gov ***

```{r}
#exporting the CSV for Derek on Aug. 28

write_csv(campaign_food_data, "data/campaign_food_data10.28.csv")

```


*** MAJOR NOTE: THIS IS ONLY 2015-2016 DATA HERE *****

We will need to gather the other years data too I believe. 


```{r}

column_names <- c("CMTE_ID", "AMNDT_IND", "REPORT_YEAR", "REPORT_TYPE", "IMAGE_NUM", "LINE_NUM", "FORM_TP_CD", "SCHED_TP_CD", "NAME", "CITY", "STATE", "ZIP_CODE", "DISBURSEMENT_DATE", "DISBURSEMENT_AMOUNT", "TRANSACTION_PGI", "PURPOSE", "CATEGORY", "CATEGORY_DESC", "MEMO_CD", "MEMO_TEXT", "ENTITY_TP", "SUB_ID", "FILE_NUM", "TRAN_ID", "BACK_REF_TRAN_ID")  # Add your column names here

new_food_data <- read_delim("~/Downloads/oppexp.txt", delim = "|", col_names = column_names)

# making the column names lower case
colnames(new_food_data) <- tolower(colnames(new_food_data))

#need to convert disbursement_date into a date field yyyy-mm-dd
#need to convert the zipcodes into a 5-digit field.


new_food_data <- new_food_data %>% 
filter(state == "DC"| state == "MD" | state == "VA")


```


use strings and then test them all togeter

```{r}
new_category_totals <- new_food_data %>% 
group_by(purpose) %>% 
count() %>% 
arrange(desc(n))


new_food_data %>% 
filter(purpose == "FOOD AND BEV")

new_food_data %>% 
filter(purpose == "MEALS")

new_food_data %>% 
  filter(purpose == "FOOD")

new_food_data %>% 
  filter(purpose == "EVENT FOOD")

new_food_data %>% 
filter(purpose == "DINING EXPENSE")

new_food_data %>% 
filter(purpose == "FOOD AND BEVERAGE") #Keep this one and combine it with "FOOD AND BEV"




#Using the filter with str_detects here
new_food_data %>% 
filter(str_detect(purpose, "FOOD"))

new_food_data %>% 
filter(str_detect(purpose, "BEVERAGE"))

new_food_data %>% 
filter(str_detect(purpose, "DINING"))

new_food_data %>% 
filter(str_detect(purpose, "MEALS"))

new_food_data %>% 
filter(str_detect(purpose, "CATERING"))

new_food_data %>% 
filter(str_detect(purpose, "DRINKS"))

new_food_data %>% 
filter(str_detect(purpose, "EVENTS"))


# filter(str_detect the terms to dmv_food when I am ready)
# and do it like this 

new_food_data %>%
  filter(str_detect(purpose, "FOOD") | 
         str_detect(purpose, "BEVERAGE") | 
         str_detect(purpose, "DINING") |
        str_detect(purpose, "MEAL") |
        str_detect(purpose, "CATERING")| 
        str_detect(purpose, "DRINK")|
        str_detect(purpose, "EVENT"))
#This procudes a tibble with 44,057 rows. 



```



```{r}
# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods_1516 <-  new_food_data %>%
  filter(str_detect(purpose, str_c(search_terms, collapse = "|")))
  #This matches the other method of using filter and str_detects and produces the same 44,057 rows.
```


```{r}

#making the date column correct
dmv_foods_1516 <- dmv_foods_1516 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods_1516 %>% 
head()


# Giving 15-16 a 5-digit zipcode

dmv_foods_1516 <- dmv_foods_1516 %>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))


```

*** Is the next step from here, importing the other years and repeating the same process? Or do I use open refine on this dataset? 

My thought is to use open refine after I am done importing/filtering every spreadsheet. ***


```{r}
#Seeing how many individuals there are.
#Does this affect what we do becuase we want to look at organizations rather than individual people. 

 dmv_foods_1516 %>%
  filter(entity_tp == "IND") %>% 
  group_by(name) %>% 
  summarise(total_amount = sum(disbursement_amount)) %>%
  arrange(desc(total_amount))

 dmv_foods_1516 %>%
  filter(entity_tp == "ORG") %>% 
  group_by(name) %>% 
  summarise(total_amount = sum(disbursement_amount)) %>%
  arrange(desc(total_amount))

```


*** Next step is to import the other years' data sets and then run the same process with the same search terms. ***

*** When I have a fuller dataset before using open refine, I should get rid of the individuals to only keep the ORG ***

*** NEXT STEPS ***
- Import dataset DONE
- Change column names (change them to match the FEC) (do this with 15-16 too) DONE
- Lowercase column names DONE
- Filter out states that aren't DC, MD, VA (Copy previous code) DONE
- Change date field to date DONE
- Change the zip code column to 5-digits DONE (done for both 22-23 and 15-16) aDONE
- put search terms into the str_detect DONE
- Check FEC site to make sure the number of rows in R is similar to what the FEC shows for that year. 

```{r}
#Loading 21-22
dmv_foods21_22 <- read_delim("~/Downloads/oppexp-2.txt", delim = "|", col_names = column_names)

dmv_foods21_22 %>% 
head()
```

```{r}

#establishing column names
column_names <- c("committee_id", "AMNDT_IND", "report_year", "report_type", "image_number", "line_number", "FORM_TP_CD", "SCHED_TP_CD", "recipient_name", "recipient_city", "recipient_state", "zip_code", "DISBURSEMENT_DATE", "DISBURSEMENT_AMOUNT", "TRANSACTION_PGI", "disbursement_description", "CATEGORY", "CATEGORY_DESC", "MEMO_CD", "MEMO_TEXT", "ENTITY_TP", "SUB_ID", "FILE_NUM", "TRAN_ID", "BACK_REF_TRAN_ID")  # Add your column names here

# making the column names lower case
colnames(dmv_foods21_22) <- tolower(colnames(dmv_foods21_22))

#need to convert disbursement_date into a date field yyyy-mm-dd
#need to convert the zipcodes into a 5-digit field.

#filtering for DC, MD, VA
dmv_foods21_22 <- dmv_foods21_22 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")

#establishing a date column
dmv_foods21_22 <- dmv_foods21_22%>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods21_22 %>% 
head()

```


```{r}
#chanign the zip_codes

dmv_foods21_22 <- dmv_foods21_22%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

```


```{r}
#Putting the search terms into the 22-23 dataframe


dmv_foods21_22 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#This procudes a tibble with 11,494 rows. 




```



```{r}
# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods21_22 <- dmv_foods21_22%>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
  #This matches the other method of using filter and str_detects and produces the same 11,494 rows.



```

Importing data from 2019-2020


*** NEXT STEPS ***
- Import dataset DONE
- Change column names (change them to match the FEC) (do this with 15-16 too) DONE
- Lowercase column names DONE
- Filter out states that aren't DC, MD, VA (Copy previous code) DONE
- Change date field to date DONE
- Change the zip code column to 5-digits DONE (done for both 22-23 and 15-16) aDONE
- put search terms into the str_detect DONE
- Check FEC site to make sure the number of rows in R is similar to what the FEC shows for that year. 


```{r}
#importing data
dmv_foods19_20 <- read_delim("~/Downloads/data1920.txt", delim = "|", col_names = column_names)

dmv_foods19_20 %>% 
head()

```

```{r}
# making the column names lower case
colnames(dmv_foods19_20) <- tolower(colnames(dmv_foods19_20))

#need to convert disbursement_date into a date field yyyy-mm-dd
#need to convert the zipcodes into a 5-digit field.

#filtering for DC, MD, VA
dmv_foods19_20 <- dmv_foods19_20 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")
```



double check this: DONE
```{r}
#establishing a date column
dmv_foods19_20 <- dmv_foods19_20 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods19_20 %>% 
head()
#why did disbursement date produce NAs?

```

```{r}

#making zip codes right

dmv_foods19_20 <- dmv_foods19_20%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods19_20 %>% 
head()
```


```{r}
#Putting the search terms into the 19-20 dataframe

dmv_foods19_20 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#This procudes a tibble with 42,918 rows. 


# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods19_20 <- dmv_foods19_20 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
  #This matches the other method of using filter and str_detects and produces the same 42,918 rows.


```

Importing data from 17-18


- Import dataset DONE
- Change column names (change them to match the FEC) DONE
- Lowercase column names DONE
- Filter out states that aren't DC, MD, VA (Copy previous code) DONE
- Change date field to date DONE
- Change the zip code column to 5-digits DONE 
- put search terms into the str_detect DONE
- Check FEC site to make sure the number of rows in R is similar to what the FEC shows for that year. 

```{r}

#importing data

 dmv_foods17_18<- read_delim("~/Downloads/data1718.txt", delim = "|", col_names = column_names)

dmv_foods17_18 %>% 
head()

#establishing column names
column_names <- c("committee_id", "AMNDT_IND", "report_year", "report_type", "image_number", "line_number", "FORM_TP_CD", "SCHED_TP_CD", "recipient_name", "recipient_city", "recipient_state", "zip_code", "DISBURSEMENT_DATE", "DISBURSEMENT_AMOUNT", "TRANSACTION_PGI", "disbursement_description", "CATEGORY", "CATEGORY_DESC", "MEMO_CD", "MEMO_TEXT", "ENTITY_TP", "SUB_ID", "FILE_NUM", "TRAN_ID", "BACK_REF_TRAN_ID")  # Add your column names here

# making the column names lower case
colnames(dmv_foods17_18) <- tolower(colnames(dmv_foods17_18))

dmv_foods17_18 %>% 
head()
```

```{r}
#filter for only DC, MD, VA

dmv_foods17_18 <- dmv_foods17_18 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")

```

```{r}
#establishing a date column
dmv_foods17_18 <- dmv_foods17_18 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods17_18 %>% 
head()


#making zip codes right
dmv_foods17_18 <- dmv_foods17_18%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods17_18 %>% 
head()

```

```{r}

dmv_foods17_18 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#produces a tibble with 56,735 rows

```

```{r}

# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods17_18 <- dmv_foods17_18 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
#matches the filter of 56,735 rows.

```

Importing data from 13-14


- Import dataset DONE
- Change column names (change them to match the FEC) DONE
- Lowercase column names DONE
- Filter out states that aren't DC, MD, VA (Copy previous code) 
- Change date field to date DONE
- Change the zip code column to 5-digits DONE
- put search terms into the str_detect DONE
- Check FEC site to make sure the number of rows in R is similar to what the FEC shows for that year. 


```{r}

dmv_foods13_14<- read_delim("~/Downloads/data1314.txt", delim = "|", col_names = column_names)

dmv_foods13_14 %>% 
head()

#establishing column names
column_names <- c("committee_id", "AMNDT_IND", "report_year", "report_type", "image_number", "line_number", "FORM_TP_CD", "SCHED_TP_CD", "recipient_name", "recipient_city", "recipient_state", "zip_code", "DISBURSEMENT_DATE", "DISBURSEMENT_AMOUNT", "TRANSACTION_PGI", "disbursement_description", "CATEGORY", "CATEGORY_DESC", "MEMO_CD", "MEMO_TEXT", "ENTITY_TP", "SUB_ID", "FILE_NUM", "TRAN_ID", "BACK_REF_TRAN_ID")  # Add your column names here

# making the column names lower case
colnames(dmv_foods13_14) <- tolower(colnames(dmv_foods13_14))

dmv_foods13_14 %>% 
head()


```



```{r}
#filter for only DC, MD, VA

dmv_foods13_14 <- dmv_foods13_14 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")

```

```{r}

#establishing a date column
dmv_foods13_14 <- dmv_foods13_14 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods13_14 %>% 
head()


#making zip codes right
dmv_foods13_14 <- dmv_foods13_14%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods13_14 %>% 
head()

```

```{r}

dmv_foods13_14 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#produces a tibble with 47,129 rows

```

```{r}

# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods13_14 <- dmv_foods13_14 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
#matches the filter of 47,129 rows.

```


Importing data from 11-12


- Import dataset DONE
- Change column names (change them to match the FEC) DONE
- Lowercase column names DONE
- Filter out states that aren't DC, MD, VA (Copy previous code) DONE
- Change date field to date DONE
- Change the zip code column to 5-digits DONE 
- put search terms into the str_detect DONE
- Check FEC site to make sure the number of rows in R is similar to what the FEC shows for that year. 


```{r}

# importing data
dmv_foods11_12<- read_delim("~/Downloads/data1112.txt", delim = "|", col_names = column_names)

dmv_foods11_12 %>% 
head()

#establishing column names
column_names <- c("committee_id", "AMNDT_IND", "report_year", "report_type", "image_number", "line_number", "FORM_TP_CD", "SCHED_TP_CD", "recipient_name", "recipient_city", "recipient_state", "zip_code", "DISBURSEMENT_DATE", "DISBURSEMENT_AMOUNT", "TRANSACTION_PGI", "disbursement_description", "CATEGORY", "CATEGORY_DESC", "MEMO_CD", "MEMO_TEXT", "ENTITY_TP", "SUB_ID", "FILE_NUM", "TRAN_ID", "BACK_REF_TRAN_ID")  # Add your column names here

# making the column names lower case
colnames(dmv_foods11_12) <- tolower(colnames(dmv_foods11_12))

dmv_foods11_12 %>% 
head()



```


```{r}

#filter for only DC, MD, VA

dmv_foods11_12 <- dmv_foods11_12 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")


```

```{r}

#establishing a date column
dmv_foods11_12 <- dmv_foods11_12 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods11_12 %>% 
head()


#making zip codes right
dmv_foods11_12 <- dmv_foods11_12%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods11_12 %>% 
head()

```


```{r}

dmv_foods11_12 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#produces a tibble with 42,479 rows



```

```{r}

# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods11_12 <- dmv_foods11_12 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
#matches the filter of 42,479 rows.

```







