---
title: "campaign_food_spending"
author: "Dylan Manfre"
date: "2023-08-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

#libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
#install.packages("ipumsr")
library(ipumsr)
```


*** Describing my first steps and initial process ***

I downloaded data from the FEC.gov with seven search term filters to relate to food. I ran some basic group_by and summarize codes to analyse the initial databsae I downloaded (link is below). Then we determined that it would be better to get the bulk data from the individual two-year cycles from 2011 until today. We picked 2011 because of a USA Today story published in 2014 that analyzed it from 2011-2014. We determined that using open refine on a larger standardized dataset would be best to clean up the organizational names. 

Below we loaded in the individual two-year cycles from 2011 to today and standarized seach_terms and column names for when we load in the data. 

 - Link: https://www.fec.gov/data/disbursements/?data_type=processed&two_year_transaction_period=2012&two_year_transaction_period=2014&two_year_transaction_period=2016&two_year_transaction_period=2018&two_year_transaction_period=2020&two_year_transaction_period=2022&two_year_transaction_period=2024&min_date=01%2F01%2F2011&max_date=12%2F31%2F2024&recipient_state=DC&recipient_state=MD&recipient_state=VA&disbursement_description=FOOD&disbursement_description=DRINKS&disbursement_description=MEALS&disbursement_description=CATERING&disbursement_description=DINING&disbursement_description=BEVERAGE&disbursement_description=MEETING&disbursement_description=EVENTS

```{r}
#establishing column names and search terms to use in each dataset

column_names <- c("committee_id", "amndt_ind", "report_year", "report_type", "image_number", "line_number", "form_tp_cd", "sched_tp_cd", "recipient_name", "recipient_city", "recipient_state", "zip_code", "disbursement_date", "disbursement_amount", "transaction_pgi", "disbursement_description", "category", "category_desc", "memo_cd", "memo_text", "entity_type", "sub_id", "file_num", "tran_id", "back_ref_tran_id")  # Add your column names here

#search_terms to use in the loops and in each dataset
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

```


```{r}
#2015-2016 data

dmv_foods15_16 <- read_delim("~/Downloads/oppexp.txt", delim = "|", col_names = column_names)


#need to convert disbursement_date into a date field yyyy-mm-dd
#need to convert the zipcodes into a 5-digit field.


dmv_foods15_16 <- dmv_foods15_16 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")



```


```{r}
#use strings and then test them all togeter

category_totals_1516 <- dmv_foods15_16 %>% 
group_by(disbursement_description) %>% 
count() %>% 
arrange(desc(n))

# filter(str_detect the terms to dmv_food when I am ready)
# and do it like this 

dmv_foods15_16 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#This procudes a tibble with 44,057 rows. 



```



```{r}
# Next step is to save the purpose terms to a search_terms variable.

dmv_foods15_16 <-  dmv_foods15_16 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
  #This matches the other method of using filter and str_detects and produces the same 44,057 rows.
```


```{r}

#making the date column correct
dmv_foods15_16 <- dmv_foods15_16 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods15_16 %>% 
head()


# Giving 15-16 a 5-digit zipcode

dmv_foods15_16 <- dmv_foods15_16 %>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))


```


```{r}
#Seeing how many individuals there are.
#Does this affect what we do becuase we want to look at organizations rather than individual people. 

 dmv_foods15_16 %>%
  filter(entity_type == "IND") %>% 
  group_by(recipient_name) %>% 
  summarise(total_amount = sum(disbursement_amount)) %>%
  arrange(desc(total_amount))

 dmv_foods15_16 %>%
  filter(entity_type == "ORG") %>% 
  group_by(recipient_name) %>% 
  summarise(total_amount = sum(disbursement_amount)) %>%
  arrange(desc(total_amount))

```


```{r}
#Loading 21-22
dmv_foods21_22 <- read_delim("~/Downloads/oppexp-2.txt", delim = "|", col_names = column_names)

dmv_foods21_22 %>% 
head()
```

```{r}

#filtering for DC, MD, VA
dmv_foods21_22 <- dmv_foods21_22 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")

#establishing a date column
dmv_foods21_22 <- dmv_foods21_22%>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods21_22 %>% 
head()

```


```{r}
#chanign the zip_codes

dmv_foods21_22 <- dmv_foods21_22%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

```


```{r}
#Putting the search terms into the 22-23 dataframe


dmv_foods21_22 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#This procudes a tibble with 11,494 rows. 




```



```{r}
# Next step is to save the purpose terms to a search_terms variable.

dmv_foods21_22 <- dmv_foods21_22%>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
  #This matches the other method of using filter and str_detects and produces the same 11,494 rows.



```

Question on 21-22: Should this be 22-23? I know that is not on the website but 23-24 is. I don't believe I have downloaded that one yet.



Importing data from 2019-2020

```{r}
#importing data
dmv_foods19_20 <- read_delim("~/Downloads/data1920.txt", delim = "|", col_names = column_names)

dmv_foods19_20 %>% 
head()

```

```{r}
#filtering for DC, MD, VA
dmv_foods19_20 <- dmv_foods19_20 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")
```



double check this: DONE
```{r}
#establishing a date column
dmv_foods19_20 <- dmv_foods19_20 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods19_20 %>% 
head()
#why did disbursement date produce NAs?

```

```{r}

#making zip codes right

dmv_foods19_20 <- dmv_foods19_20%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods19_20 %>% 
head()
```


```{r}
#Putting the search terms into the 19-20 dataframe

dmv_foods19_20 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#This procudes a tibble with 42,918 rows. 

dmv_foods19_20 <- dmv_foods19_20 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
  #This matches the other method of using filter and str_detects and produces the same 42,918 rows.


```

Importing data from 17-18


```{r}

#importing data

 dmv_foods17_18<- read_delim("~/Downloads/data1718.txt", delim = "|", col_names = column_names)

dmv_foods17_18 %>% 
head()
```

```{r}
#filter for only DC, MD, VA

dmv_foods17_18 <- dmv_foods17_18 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")

```

```{r}
#establishing a date column
dmv_foods17_18 <- dmv_foods17_18 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods17_18 %>% 
head()


#making zip codes right
dmv_foods17_18 <- dmv_foods17_18%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods17_18 %>% 
head()

```

```{r}

dmv_foods17_18 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#produces a tibble with 56,735 rows

```

```{r}

# Next step is to save the purpose terms to a search_terms variable.
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

dmv_foods17_18 <- dmv_foods17_18 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
#matches the filter of 56,735 rows.

```

Importing data from 13-14

```{r}

dmv_foods13_14<- read_delim("~/Downloads/data1314.txt", delim = "|", col_names = column_names)

dmv_foods13_14 %>% 
head()

```



```{r}
#filter for only DC, MD, VA

dmv_foods13_14 <- dmv_foods13_14 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")

```

```{r}

#establishing a date column
dmv_foods13_14 <- dmv_foods13_14 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods13_14 %>% 
head()


#making zip codes right
dmv_foods13_14 <- dmv_foods13_14%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods13_14 %>% 
head()

```

```{r}

dmv_foods13_14 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#produces a tibble with 47,129 rows

```

```{r}

#Plugging in the search terms
dmv_foods13_14 <- dmv_foods13_14 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
#matches the filter of 47,129 rows.

```


```{r}

# importing data
dmv_foods11_12<- read_delim("~/Downloads/data1112.txt", delim = "|", col_names = column_names)

dmv_foods11_12 %>% 
head()

```

```{r}

#filter for only DC, MD, VA

dmv_foods11_12 <- dmv_foods11_12 %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA")


```

```{r}

#establishing a date column
dmv_foods11_12 <- dmv_foods11_12 %>%  mutate(disbursement_date=mdy(disbursement_date))

dmv_foods11_12 %>% 
head()


#making zip codes right
dmv_foods11_12 <- dmv_foods11_12%>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L))

dmv_foods11_12 %>% 
head()

```


```{r}

dmv_foods11_12 %>%
  filter(str_detect(disbursement_description, "FOOD") | 
         str_detect(disbursement_description, "BEVERAGE") | 
         str_detect(disbursement_description, "DINING") |
        str_detect(disbursement_description, "MEAL") |
        str_detect(disbursement_description, "CATERING")| 
        str_detect(disbursement_description, "DRINK")|
        str_detect(disbursement_description, "EVENT"))
#produces a tibble with 42,479 rows



```

```{r}

# Next step is to save the purpose terms to a search_terms variable.
dmv_foods11_12 <- dmv_foods11_12 %>%
  filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
#matches the filter of 42,479 rows.

```



What I think the next steps should be after Derek looks at the code

1. Derek looks at code and provides comments
2. Combine all the datasets to make a master set showing 2011-today.
3. Add in the committee_id to the list so we can see the committees on the transactions.
4. Filter out the individuals because we only want to see places of business. 
5. Use open refine to standardize the business names and make sure they are all correct.
6. Use some of the code I wrote for the Booker/Wawa piece to gather info about the DMV spending.
7. Focus on the zip_codes surrounding Centeral/W. Maryland, DC and northern Virginia to establish DMV.
8. Analyze the important committees as well as the resturants and see what questions arise.
    - Does this place frequently get politicans outside of the DMV (Check master set)
    - Is this a well-known place or just for politicans.
    - Does the House of Reps eat at places the Senate doesn't?
    - Does Biden factor into this at all?

----------------------

General things
- makes self a readme file (an intro to the project elevator pitch)
- Good thing for me to do is to clean up the early work (if I have code not using anymore, I can repalce it with sentence that describe what I was trying to do. Include links and things I've learned.)
- Where I start the bulk downloads: I should add narrative to this saying heres why I added it.
- When I define a variable like search_terms. Define them once and then use again. Not repeatedly
- If im looking for a cleaner way to do this, I can turn this into a loop and have each cycle be a loop. 

- Next steps are good. Committee master, will load the file. 

-----------------------

Today's steps
Replace the older stuff, describing what I did -- DONE
Clean up the repating code by eliminating what is duplicates. (defining a variable once) -- DONE
Think of the steps that I need to put in the loop and put them in order for every cycle.

Steps and writing code for the loop
column_names
search_terms
load data
filter for DMV
zip_code to be 5 digits
making dates yyyy-mm-dd
Add the search_terms to the filter(str_detect


```{r}
#establishing and trying out things for the loop

dmv_foods_combined <- tibble()

# Define a list of years
cycles <- c('1112', '1314', '1516','1718','1920','2122','2324')
# Create a for loop to execute functions
for (cycle in cycles) {
  
    # need to build the path to the .txt file
    path <- paste0("~/Downloads/data", cycle,".txt")
    print(path)
    dmv_food <- read_delim(path, delim = "|", col_names = column_names)
    dmv_food_filtered <- dmv_food %>% 
    filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA") %>%
    filter(entity_type != "IND") %>% 
    mutate(zip_code = str_sub(zip_code, start=1L, end=5L)) %>%
    mutate(disbursement_date=mdy(disbursement_date)) %>%
    filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
    dmv_foods_combined <- bind_rows(dmv_foods_combined, dmv_food_filtered)
}


# fix the dates that havent happened yet and I can do that by looking at the image number on FEC. 


# FOR OPEN REFINE I WANT A LIST OF UNIQUE RESTURANTS. 

#RETAIN HOW IT ORIGINALLY APPEARS AND THEN MAKE A COPY OF THE COLUMN. 


dmv_foods_combined %>% 
group_by(entity_type) %>% 
count()


CAN	438	candidates		
CCM	87			
COM	1281			
ORG	272382			
PAC	2620			
PTY

```












#coding out the loop ... tried to make this one big and then... statement.

column_names <- c("committee_id", "amndt_ind", "report_year", "report_type", "image_number", "line_number", "form_tp_cd", "sched_tp_cd", "recipient_name", "recipient_city", "recipient_state", "zip_code", "disbursement_date", "disbursement_amount", "transaction_pgi", "disbursement_description", "category", "category_desc", "memo_cd", "memo_text", "entity_type", "sub_id", "file_num", "tran_id", "back_ref_tran_id") %>% 
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT") %>% 
#data_frame< - read_delim("~/Downloads/data_frame", delim = "|", col_names = column_names) %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA") %>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L)) %>% 
mutate(disbursement_date=mdy(disbursement_date)) %>% 
filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))






```






