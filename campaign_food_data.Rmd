---
title: "campaign_food_spending"
author: "Dylan Manfre"
date: "2023-08-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

#libraries
library(tidyverse)
library(tidycensus)
library(janitor)
library(lubridate)
#install.packages("ipumsr")
library(ipumsr)
```


*** Describing my first steps and initial process ***

I downloaded data from the FEC.gov with seven search term filters to relate to food. I ran some basic group_by and summarize codes to analyse the initial databsae I downloaded (link is below). Then we determined that it would be better to get the bulk data from the individual two-year cycles from 2011 until today. We picked 2011 because of a USA Today story published in 2014 that analyzed it from 2011-2014. We determined that using open refine on a larger standardized dataset would be best to clean up the organizational names. 

Below we loaded in the individual two-year cycles from 2011 to today and standarized seach_terms and column names for when we load in the data. 

 - Link: https://www.fec.gov/data/disbursements/?data_type=processed&two_year_transaction_period=2012&two_year_transaction_period=2014&two_year_transaction_period=2016&two_year_transaction_period=2018&two_year_transaction_period=2020&two_year_transaction_period=2022&two_year_transaction_period=2024&min_date=01%2F01%2F2011&max_date=12%2F31%2F2024&recipient_state=DC&recipient_state=MD&recipient_state=VA&disbursement_description=FOOD&disbursement_description=DRINKS&disbursement_description=MEALS&disbursement_description=CATERING&disbursement_description=DINING&disbursement_description=BEVERAGE&disbursement_description=MEETING&disbursement_description=EVENTS

```{r}
#establishing column names and search terms to use in each dataset

column_names <- c("committee_id", "amndt_ind", "report_year", "report_type", "image_number", "line_number", "form_tp_cd", "sched_tp_cd", "recipient_name", "recipient_city", "recipient_state", "zip_code", "disbursement_date", "disbursement_amount", "transaction_pgi", "disbursement_description", "category", "category_desc", "memo_cd", "memo_text", "entity_type", "sub_id", "file_num", "tran_id", "back_ref_tran_id")  # Add your column names here

#search_terms to use in the loops and in each dataset
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT")

```

What I think the next steps should be after Derek looks at the code

1. Derek looks at code and provides comments
2. Combine all the datasets to make a master set showing 2011-today.
3. Add in the committee_id to the list so we can see the committees on the transactions.
4. Filter out the individuals because we only want to see places of business. 
5. Use open refine to standardize the business names and make sure they are all correct.
6. Use some of the code I wrote for the Booker/Wawa piece to gather info about the DMV spending.
7. Focus on the zip_codes surrounding Centeral/W. Maryland, DC and northern Virginia to establish DMV.
8. Analyze the important committees as well as the resturants and see what questions arise.
    - Does this place frequently get politicans outside of the DMV (Check master set)
    - Is this a well-known place or just for politicans.
    - Does the House of Reps eat at places the Senate doesn't?
    - Does Biden factor into this at all?

----------------------

General things
- makes self a readme file (an intro to the project elevator pitch)
- Good thing for me to do is to clean up the early work (if I have code not using anymore, I can repalce it with sentence that describe what I was trying to do. Include links and things I've learned.)
- Where I start the bulk downloads: I should add narrative to this saying heres why I added it.
- When I define a variable like search_terms. Define them once and then use again. Not repeatedly
- If im looking for a cleaner way to do this, I can turn this into a loop and have each cycle be a loop. 

- Next steps are good. Committee master, will load the file. 

-----------------------

Today's steps
Replace the older stuff, describing what I did -- DONE
Clean up the repating code by eliminating what is duplicates. (defining a variable once) -- DONE
Think of the steps that I need to put in the loop and put them in order for every cycle.

Steps and writing code for the loop
column_names
search_terms
load data
filter for DMV
zip_code to be 5 digits
making dates yyyy-mm-dd
Add the search_terms to the filter(str_detect
-----------------------------------------------


The loop establishes a list of functions to run on each dataset. The cycles value is populated with the years. Then the paste0 saved to the path, has the file path.
Then It reads in the file, filters out IND and all staes not DC, MD and VA. It formats the zip_code column, disbursement_date column and search_terms to be proper. THen it binds all the rows together. 


```{r}
#establishing and trying out things for the loop

dmv_foods_combined <- tibble()

# Define a list of years
cycles <- c('1112', '1314', '1516','1718','1920','2122','2324')
# Create a for loop to execute functions
for (cycle in cycles) {
  
    # need to build the path to the .txt file
    path <- paste0("~/Downloads/data", cycle,".txt")
    print(path)
    dmv_food <- read_delim(path, delim = "|", col_names = column_names)
    dmv_food_filtered <- dmv_food %>% 
    filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA") %>%
    filter(entity_type != "IND") %>% 
    mutate(zip_code = str_sub(zip_code, start=1L, end=5L)) %>%
    mutate(disbursement_date=mdy(disbursement_date)) %>%
    filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))
    dmv_foods_combined <- bind_rows(dmv_foods_combined, dmv_food_filtered)
}


# fix the dates that havent happened yet and I can do that by looking at the image number on FEC. 


# FOR OPEN REFINE I WANT A LIST OF UNIQUE RESTURANTS. 

#RETAIN HOW IT ORIGINALLY APPEARS AND THEN MAKE A COPY OF THE COLUMN.


write_csv(dmv_foods_combined, "data/dmv_foods_combined.csv")

```


```{r}
#What are thte entity types

dmv_foods_combined %>% 
group_by(entity_type) %>% 
count()
```












#coding out the loop ... tried to make this one big and then... statement.

column_names <- c("committee_id", "amndt_ind", "report_year", "report_type", "image_number", "line_number", "form_tp_cd", "sched_tp_cd", "recipient_name", "recipient_city", "recipient_state", "zip_code", "disbursement_date", "disbursement_amount", "transaction_pgi", "disbursement_description", "category", "category_desc", "memo_cd", "memo_text", "entity_type", "sub_id", "file_num", "tran_id", "back_ref_tran_id") %>% 
search_terms <- c("FOOD", "BEVERAGE", "DINING", "MEAL", "CATERING", "DRINK", "EVENT") %>% 
#data_frame< - read_delim("~/Downloads/data_frame", delim = "|", col_names = column_names) %>% 
filter(recipient_state == "DC"| recipient_state == "MD" | recipient_state == "VA") %>% 
mutate(zip_code = str_sub(zip_code, start=1L, end=5L)) %>% 
mutate(disbursement_date=mdy(disbursement_date)) %>% 
filter(str_detect(disbursement_description, str_c(search_terms, collapse = "|")))






```






